{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import altair as alt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('data_server')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save a vega-lite spec and a PNG blob for each plot in the notebook\n",
    "alt.renderers.enable('mimetype')\n",
    "# Handle large data sets without embedding them in the notebook\n",
    "alt.data_transformers.enable('data_server')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-01-01 01:00:00</th>\n",
       "      <td>30393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 02:00:00</th>\n",
       "      <td>29265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 03:00:00</th>\n",
       "      <td>28357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 04:00:00</th>\n",
       "      <td>27899.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 05:00:00</th>\n",
       "      <td>28057.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      target\n",
       "Datetime                    \n",
       "2002-01-01 01:00:00  30393.0\n",
       "2002-01-01 02:00:00  29265.0\n",
       "2002-01-01 03:00:00  28357.0\n",
       "2002-01-01 04:00:00  27899.0\n",
       "2002-01-01 05:00:00  28057.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv('data/PJME_hourly.csv')\n",
    "\n",
    "# Remove spaces from column names\n",
    "df.columns = df.columns.str.replace(' ', '')\n",
    "\n",
    "# Convert Datetime column to datetime data type\n",
    "df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "\n",
    "# Set index to datetime column\n",
    "df = df.set_index('Datetime')\n",
    "\n",
    "# Sort the index to ascending order\n",
    "df = df.sort_index()\n",
    "\n",
    "# Rename the PJME_MW column to target column\n",
    "df = df.rename(columns={'PJME_MW': 'target'})\n",
    "\n",
    "# Check head of the resulting dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116292, 1)\n",
      "(29074, 1)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, shuffle=False, random_state=123)\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data - Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the raw data\n",
    "def plot_data(data, x_axis, y_axis):\n",
    "    \"\"\"\n",
    "    Plots line chart of the time series data (y-axis) against time (x-axis)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: pd.DataFrame\n",
    "        input dataframe\n",
    "    x_axis: str\n",
    "        the name of the time(datetime) column \n",
    "    y_axis: str\n",
    "        the name of the time series data column\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    lines: altair.vegalite.v4.api.Chart\n",
    "        altair chart object \n",
    "    \"\"\"\n",
    "    data = data.reset_index()\n",
    "    lines = alt.Chart(data).mark_line().encode(\n",
    "        x=alt.X(x_axis),\n",
    "        y=alt.Y(y_axis)\n",
    "    ).properties(\n",
    "        width=700,\n",
    "        height=250\n",
    "    )\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v4+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v4.8.1.json",
       "config": {
        "view": {
         "continuousHeight": 300,
         "continuousWidth": 400
        }
       },
       "data": {
        "url": "http://localhost:20822/b9335396beb1735a7907083fcce6b1ea.json"
       },
       "encoding": {
        "x": {
         "field": "Datetime",
         "type": "temporal"
        },
        "y": {
         "field": "target",
         "type": "quantitative"
        }
       },
       "height": 250,
       "mark": "line",
       "width": 700
      },
      "text/plain": [
       "<VegaLite 4 object>\n",
       "\n",
       "If you see this message, it means the renderer has not been properly enabled\n",
       "for the frontend that you are using. For more information, see\n",
       "https://altair-viz.github.io/user_guide/troubleshooting.html\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_data(df_train, x_axis='Datetime', y_axis='target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add lags\n",
    "def generate_lags(df, num_lags):\n",
    "    \"\"\"\n",
    "    Creates new features which are lags of the target variable\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        input dataframe\n",
    "    num_lags: int\n",
    "        the number of lags\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    df_tmp: pd.DataFrame\n",
    "        dataframe with lagged features created\n",
    "    \"\"\"\n",
    "    df_tmp = df.copy()\n",
    "    for n in range(1, num_lags+1):\n",
    "        df_tmp[f'lag{n}'] = df_tmp['target'].shift(n)\n",
    "    df_tmp = df_tmp.iloc[num_lags:]\n",
    "    return df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mt/bt06kkrx6l95m_pgdc87jxy00000gn/T/ipykernel_89321/1981978083.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tmp[f'lag{n}'] = df_tmp['target'].shift(n)\n"
     ]
    }
   ],
   "source": [
    "tot_lags = 100\n",
    "df_train = generate_lags(df=df_train, num_lags=tot_lags)\n",
    "df_test = generate_lags(df=df_test, num_lags=tot_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>lag1</th>\n",
       "      <th>lag2</th>\n",
       "      <th>lag3</th>\n",
       "      <th>lag4</th>\n",
       "      <th>lag5</th>\n",
       "      <th>lag6</th>\n",
       "      <th>lag7</th>\n",
       "      <th>lag8</th>\n",
       "      <th>lag9</th>\n",
       "      <th>...</th>\n",
       "      <th>lag91</th>\n",
       "      <th>lag92</th>\n",
       "      <th>lag93</th>\n",
       "      <th>lag94</th>\n",
       "      <th>lag95</th>\n",
       "      <th>lag96</th>\n",
       "      <th>lag97</th>\n",
       "      <th>lag98</th>\n",
       "      <th>lag99</th>\n",
       "      <th>lag100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-04-17 23:00:00</th>\n",
       "      <td>26303.0</td>\n",
       "      <td>28271.0</td>\n",
       "      <td>29280.0</td>\n",
       "      <td>28433.0</td>\n",
       "      <td>28194.0</td>\n",
       "      <td>28563.0</td>\n",
       "      <td>28783.0</td>\n",
       "      <td>28729.0</td>\n",
       "      <td>28923.0</td>\n",
       "      <td>29271.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20700.0</td>\n",
       "      <td>20813.0</td>\n",
       "      <td>21319.0</td>\n",
       "      <td>22246.0</td>\n",
       "      <td>23952.0</td>\n",
       "      <td>26369.0</td>\n",
       "      <td>28742.0</td>\n",
       "      <td>30295.0</td>\n",
       "      <td>29173.0</td>\n",
       "      <td>28476.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-18 00:00:00</th>\n",
       "      <td>24124.0</td>\n",
       "      <td>26303.0</td>\n",
       "      <td>28271.0</td>\n",
       "      <td>29280.0</td>\n",
       "      <td>28433.0</td>\n",
       "      <td>28194.0</td>\n",
       "      <td>28563.0</td>\n",
       "      <td>28783.0</td>\n",
       "      <td>28729.0</td>\n",
       "      <td>28923.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21212.0</td>\n",
       "      <td>20700.0</td>\n",
       "      <td>20813.0</td>\n",
       "      <td>21319.0</td>\n",
       "      <td>22246.0</td>\n",
       "      <td>23952.0</td>\n",
       "      <td>26369.0</td>\n",
       "      <td>28742.0</td>\n",
       "      <td>30295.0</td>\n",
       "      <td>29173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-18 01:00:00</th>\n",
       "      <td>22361.0</td>\n",
       "      <td>24124.0</td>\n",
       "      <td>26303.0</td>\n",
       "      <td>28271.0</td>\n",
       "      <td>29280.0</td>\n",
       "      <td>28433.0</td>\n",
       "      <td>28194.0</td>\n",
       "      <td>28563.0</td>\n",
       "      <td>28783.0</td>\n",
       "      <td>28729.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23033.0</td>\n",
       "      <td>21212.0</td>\n",
       "      <td>20700.0</td>\n",
       "      <td>20813.0</td>\n",
       "      <td>21319.0</td>\n",
       "      <td>22246.0</td>\n",
       "      <td>23952.0</td>\n",
       "      <td>26369.0</td>\n",
       "      <td>28742.0</td>\n",
       "      <td>30295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-18 02:00:00</th>\n",
       "      <td>21235.0</td>\n",
       "      <td>22361.0</td>\n",
       "      <td>24124.0</td>\n",
       "      <td>26303.0</td>\n",
       "      <td>28271.0</td>\n",
       "      <td>29280.0</td>\n",
       "      <td>28433.0</td>\n",
       "      <td>28194.0</td>\n",
       "      <td>28563.0</td>\n",
       "      <td>28783.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26397.0</td>\n",
       "      <td>23033.0</td>\n",
       "      <td>21212.0</td>\n",
       "      <td>20700.0</td>\n",
       "      <td>20813.0</td>\n",
       "      <td>21319.0</td>\n",
       "      <td>22246.0</td>\n",
       "      <td>23952.0</td>\n",
       "      <td>26369.0</td>\n",
       "      <td>28742.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-18 03:00:00</th>\n",
       "      <td>20619.0</td>\n",
       "      <td>21235.0</td>\n",
       "      <td>22361.0</td>\n",
       "      <td>24124.0</td>\n",
       "      <td>26303.0</td>\n",
       "      <td>28271.0</td>\n",
       "      <td>29280.0</td>\n",
       "      <td>28433.0</td>\n",
       "      <td>28194.0</td>\n",
       "      <td>28563.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28384.0</td>\n",
       "      <td>26397.0</td>\n",
       "      <td>23033.0</td>\n",
       "      <td>21212.0</td>\n",
       "      <td>20700.0</td>\n",
       "      <td>20813.0</td>\n",
       "      <td>21319.0</td>\n",
       "      <td>22246.0</td>\n",
       "      <td>23952.0</td>\n",
       "      <td>26369.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      target     lag1     lag2     lag3     lag4     lag5  \\\n",
       "Datetime                                                                    \n",
       "2015-04-17 23:00:00  26303.0  28271.0  29280.0  28433.0  28194.0  28563.0   \n",
       "2015-04-18 00:00:00  24124.0  26303.0  28271.0  29280.0  28433.0  28194.0   \n",
       "2015-04-18 01:00:00  22361.0  24124.0  26303.0  28271.0  29280.0  28433.0   \n",
       "2015-04-18 02:00:00  21235.0  22361.0  24124.0  26303.0  28271.0  29280.0   \n",
       "2015-04-18 03:00:00  20619.0  21235.0  22361.0  24124.0  26303.0  28271.0   \n",
       "\n",
       "                        lag6     lag7     lag8     lag9  ...    lag91  \\\n",
       "Datetime                                                 ...            \n",
       "2015-04-17 23:00:00  28783.0  28729.0  28923.0  29271.0  ...  20700.0   \n",
       "2015-04-18 00:00:00  28563.0  28783.0  28729.0  28923.0  ...  21212.0   \n",
       "2015-04-18 01:00:00  28194.0  28563.0  28783.0  28729.0  ...  23033.0   \n",
       "2015-04-18 02:00:00  28433.0  28194.0  28563.0  28783.0  ...  26397.0   \n",
       "2015-04-18 03:00:00  29280.0  28433.0  28194.0  28563.0  ...  28384.0   \n",
       "\n",
       "                       lag92    lag93    lag94    lag95    lag96    lag97  \\\n",
       "Datetime                                                                    \n",
       "2015-04-17 23:00:00  20813.0  21319.0  22246.0  23952.0  26369.0  28742.0   \n",
       "2015-04-18 00:00:00  20700.0  20813.0  21319.0  22246.0  23952.0  26369.0   \n",
       "2015-04-18 01:00:00  21212.0  20700.0  20813.0  21319.0  22246.0  23952.0   \n",
       "2015-04-18 02:00:00  23033.0  21212.0  20700.0  20813.0  21319.0  22246.0   \n",
       "2015-04-18 03:00:00  26397.0  23033.0  21212.0  20700.0  20813.0  21319.0   \n",
       "\n",
       "                       lag98    lag99   lag100  \n",
       "Datetime                                        \n",
       "2015-04-17 23:00:00  30295.0  29173.0  28476.0  \n",
       "2015-04-18 00:00:00  28742.0  30295.0  29173.0  \n",
       "2015-04-18 01:00:00  26369.0  28742.0  30295.0  \n",
       "2015-04-18 02:00:00  23952.0  26369.0  28742.0  \n",
       "2015-04-18 03:00:00  22246.0  23952.0  26369.0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train and y_train: ((116192, 100), (116192,))\n",
      "Shape of X_test and y_test: ((28974, 100), (28974,))\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = (\n",
    "    df_train.drop(columns=['target']),\n",
    "    df_train['target']\n",
    ")\n",
    "X_test, y_test = (\n",
    "    df_test.drop(columns=['target']),\n",
    "    df_test['target']\n",
    ")\n",
    "\n",
    "# Print shapes of the resulting train and test data sets\n",
    "print(f'Shape of X_train and y_train: {X_train.shape, y_train.shape}')\n",
    "print(f'Shape of X_test and y_test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Using Pipeline Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Transformer for Automated Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniveriateTimeSeriesAddFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_lags=10):\n",
    "        self.num_lags = num_lags\n",
    "        \n",
    "    def __extract_features(self, X):\n",
    "        \"\"\"\n",
    "        Creates new features from timestamp\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: pd.DataFrame\n",
    "            input dataframe\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        df_features: pd.DataFrame\n",
    "            dataframe with new features created\n",
    "        \"\"\"\n",
    "        df_features = X.copy()\n",
    "        df_features = (\n",
    "                df_features\n",
    "                .assign(hour = df_features.index.hour)\n",
    "                .assign(day = df_features.index.day)\n",
    "                .assign(month = df_features.index.month)\n",
    "                .assign(day_of_week = df_features.index.dayofweek)\n",
    "                # .assign(week_of_year = df.index.isocalendar().week)\n",
    "        )\n",
    "        df_features = df_features.reset_index()\n",
    "        return df_features\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        df_features = X.copy()\n",
    "        df_features = self.__extract_features(df_features)\n",
    "        df_features = df_features.iloc[:,1:]\n",
    "        return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Pipeline(\n",
    "    [\n",
    "        ('add_lag_step', UniveriateTimeSeriesAddFeatures(num_lags=10)),\n",
    "        ('stdscaler', StandardScaler())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(true, pred):\n",
    "    return 100.0 * np.mean(np.abs((pred - true) / true))\n",
    "\n",
    "\n",
    "# make a scorer function that we can pass into cross-validation\n",
    "mape_scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "scoring_metrics = {\n",
    "    \"neg RMSE\": \"neg_root_mean_squared_error\",\n",
    "    \"r2\": \"r2\",\n",
    "    \"mape\": mape_scorer,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to collate results\n",
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.030 (+/- 0.043)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.002 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_neg RMSE</th>\n",
       "      <td>-6439.362 (+/- 250.618)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_neg RMSE</th>\n",
       "      <td>-6434.573 (+/- 64.006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_r2</th>\n",
       "      <td>-0.007 (+/- 0.006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_r2</th>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mape</th>\n",
       "      <td>-15.878 (+/- 0.621)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_mape</th>\n",
       "      <td>-15.857 (+/- 0.096)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Dummy\n",
       "fit_time              0.030 (+/- 0.043)\n",
       "score_time            0.002 (+/- 0.001)\n",
       "test_neg RMSE   -6439.362 (+/- 250.618)\n",
       "train_neg RMSE   -6434.573 (+/- 64.006)\n",
       "test_r2              -0.007 (+/- 0.006)\n",
       "train_r2              0.000 (+/- 0.000)\n",
       "test_mape           -15.878 (+/- 0.621)\n",
       "train_mape          -15.857 (+/- 0.096)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = DummyRegressor()\n",
    "\n",
    "results[\"Dummy\"] = mean_std_cross_val_scores(\n",
    "    dummy, X_train, y_train, return_train_score=True, scoring=scoring_metrics\n",
    ")\n",
    "\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_ridge = make_pipeline(preprocessor, Ridge(random_state=123))\n",
    "pipe_xgb = make_pipeline(preprocessor, XGBRegressor(random_state=123))\n",
    "pipe_rf = make_pipeline(preprocessor, RandomForestRegressor(random_state=123))\n",
    "\n",
    "models = {\n",
    "    'ridge': pipe_ridge,\n",
    "    'xgboost': pipe_xgb,\n",
    "    'rf_regressor': pipe_rf\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy</th>\n",
       "      <th>ridge</th>\n",
       "      <th>xgboost</th>\n",
       "      <th>rf_regressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.030 (+/- 0.043)</td>\n",
       "      <td>0.236 (+/- 0.161)</td>\n",
       "      <td>25.680 (+/- 1.577)</td>\n",
       "      <td>640.237 (+/- 3.625)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.002 (+/- 0.001)</td>\n",
       "      <td>0.040 (+/- 0.025)</td>\n",
       "      <td>0.086 (+/- 0.009)</td>\n",
       "      <td>0.994 (+/- 0.111)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_neg RMSE</th>\n",
       "      <td>-6439.362 (+/- 250.618)</td>\n",
       "      <td>-326.362 (+/- 30.261)</td>\n",
       "      <td>-374.793 (+/- 20.079)</td>\n",
       "      <td>-356.426 (+/- 22.760)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_neg RMSE</th>\n",
       "      <td>-6434.573 (+/- 64.006)</td>\n",
       "      <td>-325.508 (+/- 8.169)</td>\n",
       "      <td>-296.067 (+/- 3.588)</td>\n",
       "      <td>-129.015 (+/- 1.060)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_r2</th>\n",
       "      <td>-0.007 (+/- 0.006)</td>\n",
       "      <td>0.997 (+/- 0.001)</td>\n",
       "      <td>0.997 (+/- 0.001)</td>\n",
       "      <td>0.997 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_r2</th>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.997 (+/- 0.000)</td>\n",
       "      <td>0.998 (+/- 0.000)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mape</th>\n",
       "      <td>-15.878 (+/- 0.621)</td>\n",
       "      <td>-0.712 (+/- 0.045)</td>\n",
       "      <td>-0.847 (+/- 0.053)</td>\n",
       "      <td>-0.735 (+/- 0.060)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_mape</th>\n",
       "      <td>-15.857 (+/- 0.096)</td>\n",
       "      <td>-0.709 (+/- 0.011)</td>\n",
       "      <td>-0.693 (+/- 0.010)</td>\n",
       "      <td>-0.263 (+/- 0.003)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Dummy                  ridge  \\\n",
       "fit_time              0.030 (+/- 0.043)      0.236 (+/- 0.161)   \n",
       "score_time            0.002 (+/- 0.001)      0.040 (+/- 0.025)   \n",
       "test_neg RMSE   -6439.362 (+/- 250.618)  -326.362 (+/- 30.261)   \n",
       "train_neg RMSE   -6434.573 (+/- 64.006)   -325.508 (+/- 8.169)   \n",
       "test_r2              -0.007 (+/- 0.006)      0.997 (+/- 0.001)   \n",
       "train_r2              0.000 (+/- 0.000)      0.997 (+/- 0.000)   \n",
       "test_mape           -15.878 (+/- 0.621)     -0.712 (+/- 0.045)   \n",
       "train_mape          -15.857 (+/- 0.096)     -0.709 (+/- 0.011)   \n",
       "\n",
       "                              xgboost           rf_regressor  \n",
       "fit_time           25.680 (+/- 1.577)    640.237 (+/- 3.625)  \n",
       "score_time          0.086 (+/- 0.009)      0.994 (+/- 0.111)  \n",
       "test_neg RMSE   -374.793 (+/- 20.079)  -356.426 (+/- 22.760)  \n",
       "train_neg RMSE   -296.067 (+/- 3.588)   -129.015 (+/- 1.060)  \n",
       "test_r2             0.997 (+/- 0.001)      0.997 (+/- 0.001)  \n",
       "train_r2            0.998 (+/- 0.000)      1.000 (+/- 0.000)  \n",
       "test_mape          -0.847 (+/- 0.053)     -0.735 (+/- 0.060)  \n",
       "train_mape         -0.693 (+/- 0.010)     -0.263 (+/- 0.003)  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for (name, model) in models.items():\n",
    "    results[name] = mean_std_cross_val_scores(\n",
    "        model, X_train, y_train, return_train_score=True, scoring=scoring_metrics\n",
    "    )\n",
    "\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Model (Example of XGBRegressor provided below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_xgb.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipe_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>target</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-04-13 19:00:00</td>\n",
       "      <td>28476.0</td>\n",
       "      <td>28647.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-04-13 20:00:00</td>\n",
       "      <td>29173.0</td>\n",
       "      <td>28639.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-04-13 21:00:00</td>\n",
       "      <td>30295.0</td>\n",
       "      <td>29738.888672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-04-13 22:00:00</td>\n",
       "      <td>28742.0</td>\n",
       "      <td>29323.021484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-04-13 23:00:00</td>\n",
       "      <td>26369.0</td>\n",
       "      <td>26618.931641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Datetime   target     predicted\n",
       "0 2015-04-13 19:00:00  28476.0  28647.218750\n",
       "1 2015-04-13 20:00:00  29173.0  28639.703125\n",
       "2 2015-04-13 21:00:00  30295.0  29738.888672\n",
       "3 2015-04-13 22:00:00  28742.0  29323.021484\n",
       "4 2015-04-13 23:00:00  26369.0  26618.931641"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_vs_pred_df = y_test.reset_index()\n",
    "actual_vs_pred_df['predicted'] = preds\n",
    "actual_vs_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57943</th>\n",
       "      <td>2018-08-02 20:00:00</td>\n",
       "      <td>predicted</td>\n",
       "      <td>44266.675781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57944</th>\n",
       "      <td>2018-08-02 21:00:00</td>\n",
       "      <td>predicted</td>\n",
       "      <td>43442.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57945</th>\n",
       "      <td>2018-08-02 22:00:00</td>\n",
       "      <td>predicted</td>\n",
       "      <td>42229.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57946</th>\n",
       "      <td>2018-08-02 23:00:00</td>\n",
       "      <td>predicted</td>\n",
       "      <td>38295.269531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57947</th>\n",
       "      <td>2018-08-03 00:00:00</td>\n",
       "      <td>predicted</td>\n",
       "      <td>34941.445312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Datetime   variable         value\n",
       "57943 2018-08-02 20:00:00  predicted  44266.675781\n",
       "57944 2018-08-02 21:00:00  predicted  43442.156250\n",
       "57945 2018-08-02 22:00:00  predicted  42229.500000\n",
       "57946 2018-08-02 23:00:00  predicted  38295.269531\n",
       "57947 2018-08-03 00:00:00  predicted  34941.445312"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_vs_pred_df_long = pd.melt(actual_vs_pred_df, id_vars='Datetime')\n",
    "\n",
    "actual_vs_pred_df_long.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v4+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v4.8.1.json",
       "config": {
        "view": {
         "continuousHeight": 300,
         "continuousWidth": 400
        }
       },
       "data": {
        "url": "http://localhost:20822/100d2a29db8ea22745c3f118c78ecb46.json"
       },
       "encoding": {
        "color": {
         "field": "variable",
         "title": "Type",
         "type": "nominal"
        },
        "x": {
         "field": "Datetime",
         "title": "Datetime",
         "type": "temporal"
        },
        "y": {
         "field": "value",
         "title": "Actual vs Predicted",
         "type": "quantitative"
        }
       },
       "mark": "line",
       "selection": {
        "selector001": {
         "bind": "scales",
         "encodings": [
          "x",
          "y"
         ],
         "type": "interval"
        }
       },
       "width": 700
      },
      "text/plain": [
       "<VegaLite 4 object>\n",
       "\n",
       "If you see this message, it means the renderer has not been properly enabled\n",
       "for the frontend that you are using. For more information, see\n",
       "https://altair-viz.github.io/user_guide/troubleshooting.html\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the actual vs predicted chart for the last 2 days of the test data period\n",
    "alt.Chart(actual_vs_pred_df_long[actual_vs_pred_df_long.Datetime > '2018-07-24']).mark_line().encode(\n",
    "    x=alt.X('Datetime', type='temporal', title='Datetime'),\n",
    "    y=alt.Y('value', type='quantitative', title='Actual vs Predicted'),\n",
    "    color=alt.Color('variable', title='Type')\n",
    ").properties(\n",
    "    width=700\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE for test set: 0.9109370478794194\n"
     ]
    }
   ],
   "source": [
    "print(f'MAPE for test set: {mape(actual_vs_pred_df[\"target\"], actual_vs_pred_df[\"predicted\"])}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae4e6b2e328c0ea4627e14bd093050c1271aa8df82847c52aa07c279e17c71ae"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('571': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
